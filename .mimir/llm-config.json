{
  "defaultProvider": "copilot",
  "providers": {
    "ollama": {
      "baseUrl": "http://localhost:11434",
      "defaultModel": "qwen3:8b",
      "models": {
        "gpt-oss": {
          "name": "gpt-oss",
          "contextWindow": 32768,
          "description": "Open-source GPT model (13B params), good balance of quality and speed",
          "recommendedFor": ["pm", "worker", "qc"],
          "config": {
            "numCtx": 32768,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "tinyllama": {
          "name": "tinyllama",
          "contextWindow": 8192,
          "description": "1.1B params, very fast inference (backup/testing only)",
          "recommendedFor": ["testing"],
          "config": {
            "numCtx": 8192,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "qwen2.5-coder:1.5b-base": {
          "name": "qwen2.5-coder:1.5b-base",
          "contextWindow": 32768,
          "description": "1.5B params coding specialist, fast inference",
          "recommendedFor": ["worker"],
          "config": {
            "numCtx": 32768,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "deepseek-coder:6.7b": {
          "name": "deepseek-coder:6.7b",
          "contextWindow": 16384,
          "description": "6.7B params coding specialist",
          "recommendedFor": ["worker"],
          "config": {
            "numCtx": 16384,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "qwen3:8b": {
          "name": "qwen3:8b",
          "contextWindow": 40960,
          "description": "8B params general model with advanced agentic capabilities, tool calling, and strong reasoning",
          "recommendedFor": ["pm", "qc"],
          "config": {
            "numCtx": 40960,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "nomic-embed-text": {
          "name": "nomic-embed-text",
          "contextWindow": 8192,
          "description": "Text embedding model for RAG search and file indexing (137M params, 768 dimensions)",
          "recommendedFor": ["embeddings", "rag", "search"],
          "config": {
            "numCtx": 8192,
            "temperature": 0.0,
            "numPredict": -1
          }
        }
      }
    },
    "copilot": {
      "baseUrl": "http://localhost:4141/v1",
      "defaultModel": "gpt-4.1",
      "models": {
        "gpt-4.1": {
          "name": "gpt-4.1",
          "contextWindow": 128000,
          "description": "OpenAI GPT-4.1 via GitHub Copilot (latest, best performance)",
          "recommendedFor": ["pm", "worker", "qc"],
          "config": {
            "maxTokens": -1,
            "temperature": 0.0
          }
        },
        "gpt-4o": {
          "name": "gpt-4o",
          "contextWindow": 128000,
          "description": "OpenAI GPT-4o via GitHub Copilot (requires active subscription)",
          "recommendedFor": ["pm"],
          "config": {
            "maxTokens": -1,
            "temperature": 0.0
          }
        }
      }
    }
  },
  "agentDefaults": {
    "pm": {
      "provider": "copilot",
      "model": "gpt-4.1",
      "rationale": "PM agents need strong reasoning for task decomposition and planning - GPT-4.1 provides superior performance"
    },
    "worker": {
      "provider": "copilot",
      "model": "gpt-4.1",
      "rationale": "Worker agents execute tasks with GPT-4.1 for consistent high-quality output"
    },
    "qc": {
      "provider": "copilot",
      "model": "gpt-4.1",
      "rationale": "QC agents validate output with GPT-4.1 for strict consistency and accuracy"
    },
    "embeddings": {
      "provider": "ollama",
      "model": "nomic-embed-text",
      "rationale": "Local embeddings for RAG search and file indexing - keep embeddings local for privacy and cost"
    }
  },
  "features": {
    "pmModelSuggestions": false,
    "_comment": "When true, PM agent can suggest specific models for tasks based on available models. When false/missing, always use agentDefaults."
  },
  "_comment": "RAG/Vector embeddings will use Ollama (local models) while agent LLM inference uses Copilot GPT-4.1. This provides best of both worlds: powerful cloud LLMs for reasoning + local embeddings for privacy/cost."
}
