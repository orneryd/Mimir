#!/bin/bash
# Ollama Model Setup Script
# Automatically pulls models configured in .mimir/llm-config.json

set -e

OLLAMA_CONTAINER="ollama_server"

echo "ğŸ¤– Setting up Ollama models from config..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# Check if Ollama container is running
if ! docker ps | grep -q $OLLAMA_CONTAINER; then
  echo "âŒ Ollama container is not running!"
  echo "   Start it with: docker-compose up -d ollama"
  exit 1
fi

echo "âœ… Ollama container is running"
echo ""

# Models to pull based on .mimir/llm-config.json agentDefaults
MODELS=(
  "qwen3:8b"                # PM/QC agent - agentic capabilities, tool calling (5.2GB)
  "qwen2.5-coder:1.5b-base" # Worker agent - fast code generation (986MB)
)

echo "ğŸ“¦ Models to install (from config):"
for model in "${MODELS[@]}"; do
  echo "   - $model"
done
echo ""

# Pull each model
for model in "${MODELS[@]}"; do
  echo "ğŸ“¥ Pulling model: $model"
  docker exec $OLLAMA_CONTAINER ollama pull $model
  echo "âœ… Successfully pulled $model"
  echo ""
done

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ¨ All models installed successfully!"
echo ""
echo "Installed models:"
docker exec $OLLAMA_CONTAINER ollama list
echo ""
echo "ğŸ’¾ Storage location: ./data/ollama/models/"
echo "ğŸ“Š Check storage usage: ./scripts/check-storage.sh"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ’¡ To pull additional models:"
echo ""
echo "   ./scripts/pull-model.sh qwen2.5-coder:7b    # Better quality (4.7GB)"
echo "   ./scripts/pull-model.sh llama3.1:8b         # General purpose (4.9GB)"
echo "   ./scripts/pull-model.sh deepseek-r1:8b      # Reasoning (5.2GB)"
echo ""
echo "ğŸš€ You can now use the agent chain:"
echo "   npm run chain \"implement authentication\""
echo ""
